{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813ff1da",
   "metadata": {},
   "source": [
    "### This is the code for the web scraping functions using pygooglenews and other packages to scrape Google News according to a matrix of factors including author name, key words found in the titles of the peer-reviewed publications, DOI's and peer-reviewed journal names. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d492c6",
   "metadata": {},
   "source": [
    "### Import pygooglenews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ddad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygooglenews import GoogleNews\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "gn = GoogleNews() # now global mode? can specify country = US"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af8138",
   "metadata": {},
   "source": [
    "### Import .csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493c85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('UseCase1_Data.csv') # must be in same repository that the jupyter notebook is in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52655304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Article_Title</th>\n",
       "      <th>Article_DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Laurel Westbrook</td>\n",
       "      <td>Doing Gender, Determining Gender: Transgender ...</td>\n",
       "      <td>10.1177/0891243213503203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan Ospina-Betancurt</td>\n",
       "      <td>The End of Compulsory Gender Verification: Is ...</td>\n",
       "      <td>10.1007/s10508-021-02073-x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Katrina Karkazis</td>\n",
       "      <td>The misuses of “biological sex”</td>\n",
       "      <td>10.1016/S0140-6736(19)32764-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vanessa Heggie</td>\n",
       "      <td>Testing sex and gender in sports; reinventing,...</td>\n",
       "      <td>10.1016/j.endeavour.2010.09.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>April Vannini</td>\n",
       "      <td>Girl, Interrupted: Interpreting Semenya’s Body...</td>\n",
       "      <td>10.1177/1532708611409536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heather Sykes</td>\n",
       "      <td>Transsexual and Transgender Policies in Sport</td>\n",
       "      <td>10.1123/wspaj.15.1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stephane Bermon</td>\n",
       "      <td>Are the New Policies on Hyperandrogenism in El...</td>\n",
       "      <td>10.1080/15265161.2013.776129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Francisco Sanchez</td>\n",
       "      <td>The New Policy on Hyperandrogenism in Elite Fe...</td>\n",
       "      <td>10.1080/00224499.2012.752429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ruth Wood</td>\n",
       "      <td>Testosterone and sport: current perspectives</td>\n",
       "      <td>10.1016/j.yhbeh.2011.09.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Emma Hilton</td>\n",
       "      <td>Transgender women in the female category of sp...</td>\n",
       "      <td>10.1007/s40279-020-01389-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Joanna Harper</td>\n",
       "      <td>Implications of a third gender for elite sports</td>\n",
       "      <td>10.1249/JSR.0000000000000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Timothy Roberts</td>\n",
       "      <td>Effect of gender affirming hormones on athleti...</td>\n",
       "      <td>10.1136/bjsports-2020-102329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ashely Bassett</td>\n",
       "      <td>The Biology of Sex and Sport</td>\n",
       "      <td>10.2106/JBJS.RVW.19.00140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alan Rogol</td>\n",
       "      <td>Genes, Gender, Hormones, and Doping in Sport: ...</td>\n",
       "      <td>doi.org/10.3389/fendo.2017.00251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Maria Jose Martinez-Patino</td>\n",
       "      <td>The unfinished race: 30 years of gender verifi...</td>\n",
       "      <td>10.1016/S0140-6736(16)30963-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Taryon Knox</td>\n",
       "      <td>Transwomen in elite sport: scientific and ethi...</td>\n",
       "      <td>10.1136/medethics-2018-105208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>John Devine</td>\n",
       "      <td>Gender, Steroids, and Fairness in Sport</td>\n",
       "      <td>10.1080/17511321.2017.1404627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Carole Hooven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Author_Name  \\\n",
       "0             Laurel Westbrook   \n",
       "1    Jonathan Ospina-Betancurt   \n",
       "2             Katrina Karkazis   \n",
       "3               Vanessa Heggie   \n",
       "4                April Vannini   \n",
       "5                Heather Sykes   \n",
       "6              Stephane Bermon   \n",
       "7            Francisco Sanchez   \n",
       "8                    Ruth Wood   \n",
       "9                  Emma Hilton   \n",
       "10               Joanna Harper   \n",
       "11             Timothy Roberts   \n",
       "12              Ashely Bassett   \n",
       "13                  Alan Rogol   \n",
       "14  Maria Jose Martinez-Patino   \n",
       "15                 Taryon Knox   \n",
       "16                 John Devine   \n",
       "17               Carole Hooven   \n",
       "\n",
       "                                        Article_Title  \\\n",
       "0   Doing Gender, Determining Gender: Transgender ...   \n",
       "1   The End of Compulsory Gender Verification: Is ...   \n",
       "2                     The misuses of “biological sex”   \n",
       "3   Testing sex and gender in sports; reinventing,...   \n",
       "4   Girl, Interrupted: Interpreting Semenya’s Body...   \n",
       "5       Transsexual and Transgender Policies in Sport   \n",
       "6   Are the New Policies on Hyperandrogenism in El...   \n",
       "7   The New Policy on Hyperandrogenism in Elite Fe...   \n",
       "8        Testosterone and sport: current perspectives   \n",
       "9   Transgender women in the female category of sp...   \n",
       "10    Implications of a third gender for elite sports   \n",
       "11  Effect of gender affirming hormones on athleti...   \n",
       "12                       The Biology of Sex and Sport   \n",
       "13  Genes, Gender, Hormones, and Doping in Sport: ...   \n",
       "14  The unfinished race: 30 years of gender verifi...   \n",
       "15  Transwomen in elite sport: scientific and ethi...   \n",
       "16            Gender, Steroids, and Fairness in Sport   \n",
       "17                                                NaN   \n",
       "\n",
       "                         Article_DOI  \n",
       "0           10.1177/0891243213503203  \n",
       "1         10.1007/s10508-021-02073-x  \n",
       "2      10.1016/S0140-6736(19)32764-3  \n",
       "3    10.1016/j.endeavour.2010.09.005  \n",
       "4           10.1177/1532708611409536  \n",
       "5               10.1123/wspaj.15.1.3  \n",
       "6       10.1080/15265161.2013.776129  \n",
       "7       10.1080/00224499.2012.752429  \n",
       "8        10.1016/j.yhbeh.2011.09.010  \n",
       "9         10.1007/s40279-020-01389-3  \n",
       "10      10.1249/JSR.0000000000000455  \n",
       "11      10.1136/bjsports-2020-102329  \n",
       "12         10.2106/JBJS.RVW.19.00140  \n",
       "13  doi.org/10.3389/fendo.2017.00251  \n",
       "14     10.1016/S0140-6736(16)30963-1  \n",
       "15     10.1136/medethics-2018-105208  \n",
       "16     10.1080/17511321.2017.1404627  \n",
       "17                               NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9fbe8a",
   "metadata": {},
   "source": [
    "### Function for scraping by author name only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "415bd262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Laurel Westbrook</td>\n",
       "      <td>Thorpe questions FINA's trans swimming ban: Th...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laurel Westbrook</td>\n",
       "      <td>Transgender Legal Battles: A Timeline - JSTOR ...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laurel Westbrook</td>\n",
       "      <td>Real Estate Transactions for Nov. 24 - Zip06.com</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laurel Westbrook</td>\n",
       "      <td>St. Tammany property transfers, Oct.18-24, 202...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laurel Westbrook</td>\n",
       "      <td>Russell Westbrook Bought a $37 Million House -...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Carole Hooven</td>\n",
       "      <td>Are There Health Benefits to Feeling Emotions?...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Carole Hooven</td>\n",
       "      <td>15 best science and environment books 2021 | S...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Carole Hooven</td>\n",
       "      <td>Study debunks one of the most damaging myths a...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Carole Hooven</td>\n",
       "      <td>Biological differences give men unfair advanta...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Carole Hooven</td>\n",
       "      <td>Benefits of Testosterone Boosting - Low Testos...</td>\n",
       "      <td>https://news.google.com/__i/rss/rd/articles/CB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Author_Name                                              title  \\\n",
       "0    Laurel Westbrook  Thorpe questions FINA's trans swimming ban: Th...   \n",
       "1    Laurel Westbrook  Transgender Legal Battles: A Timeline - JSTOR ...   \n",
       "2    Laurel Westbrook   Real Estate Transactions for Nov. 24 - Zip06.com   \n",
       "3    Laurel Westbrook  St. Tammany property transfers, Oct.18-24, 202...   \n",
       "4    Laurel Westbrook  Russell Westbrook Bought a $37 Million House -...   \n",
       "..                ...                                                ...   \n",
       "883     Carole Hooven  Are There Health Benefits to Feeling Emotions?...   \n",
       "884     Carole Hooven  15 best science and environment books 2021 | S...   \n",
       "885     Carole Hooven  Study debunks one of the most damaging myths a...   \n",
       "886     Carole Hooven  Biological differences give men unfair advanta...   \n",
       "887     Carole Hooven  Benefits of Testosterone Boosting - Low Testos...   \n",
       "\n",
       "                                                  link  \n",
       "0    https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "1    https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "2    https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "3    https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "4    https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "..                                                 ...  \n",
       "883  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "884  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "885  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "886  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "887  https://news.google.com/__i/rss/rd/articles/CB...  \n",
       "\n",
       "[888 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search = gn.search(‘author name’) #search by author name\n",
    "def scraping_author(df):\n",
    "    '''This function scrapes google news for anything matching the \n",
    "    scholarly author name in df'''\n",
    "    stories = []\n",
    "    for i in range(len(df)):\n",
    "        search = gn.search(df.iloc[i].loc['Author_Name'])\n",
    "        newsitem = search['entries']\n",
    "        for item in newsitem:\n",
    "            story = {\n",
    "                'Author_Name': df.iloc[i].loc['Author_Name'],\n",
    "                'title': item.title,\n",
    "                'link': item.link\n",
    "            }\n",
    "            \n",
    "            stories.append(story)    \n",
    "    return stories\n",
    "scraping_author_df = pd.DataFrame(scraping_author(df)) # this puts the output in a long form dataframe\n",
    "\n",
    "scraping_author_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb213318",
   "metadata": {},
   "source": [
    "### Function for scraping by DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a63b96",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "quote_from_bytes() expected bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-832dbf9883c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mstories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mscraping_doi_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscraping_doi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this puts the output in a long form dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mscraping_doi_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-832dbf9883c9>\u001b[0m in \u001b[0;36mscraping_doi\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Article_DOI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mnewsitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entries'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewsitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pygooglenews/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, query, helper, when, from_, to_, proxies, scraping_bee)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhelper\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__search_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0msearch_ceid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__ceid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pygooglenews/__init__.py\u001b[0m in \u001b[0;36m__search_helper\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__search_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__from_to_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/parse.py\u001b[0m in \u001b[0;36mquote_plus\u001b[0;34m(string, safe, encoding, errors)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/parse.py\u001b[0m in \u001b[0;36mquote\u001b[0;34m(string, safe, encoding, errors)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quote() doesn't support 'errors' for bytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mquote_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/parse.py\u001b[0m in \u001b[0;36mquote_from_bytes\u001b[0;34m(bs, safe)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \"\"\"\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quote_from_bytes() expected bytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: quote_from_bytes() expected bytes"
     ]
    }
   ],
   "source": [
    "# search = gn.search(‘Article_DOI’) #search by reference to article DOI\n",
    "def scraping_doi(df):\n",
    "    '''This function scrapes google news for anything matching the \n",
    "    scholarly DOI in df'''\n",
    "    stories = []\n",
    "    for i in range(len(df)):\n",
    "        search = gn.search(df.iloc[i].loc['Article_DOI'])\n",
    "        newsitem = search['entries']\n",
    "        for item in newsitem:\n",
    "            story = {\n",
    "                'Article_DOI': df.iloc[i].loc['Article_DOI'],\n",
    "                'title': item.title,\n",
    "                'link': item.link\n",
    "            }\n",
    "            \n",
    "            stories.append(story)    \n",
    "    return stories\n",
    "scraping_doi_df = pd.DataFrame(scraping_doi(df)) # this puts the output in a long form dataframe\n",
    "\n",
    "scraping_doi_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864f5e6",
   "metadata": {},
   "source": [
    "### Function for scraping by exact article title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb2dfcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "quote_from_bytes() expected bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-86a8432572ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mstories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mscraping_title_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscraping_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this puts the output in a long form dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-86a8432572ba>\u001b[0m in \u001b[0;36mscraping_title\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Article_Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mnewsitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entries'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnewsitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pygooglenews/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, query, helper, when, from_, to_, proxies, scraping_bee)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhelper\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__search_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0msearch_ceid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__ceid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pygooglenews/__init__.py\u001b[0m in \u001b[0;36m__search_helper\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__search_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__from_to_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/parse.py\u001b[0m in \u001b[0;36mquote_plus\u001b[0;34m(string, safe, encoding, errors)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/parse.py\u001b[0m in \u001b[0;36mquote\u001b[0;34m(string, safe, encoding, errors)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quote() doesn't support 'errors' for bytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mquote_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/urllib/parse.py\u001b[0m in \u001b[0;36mquote_from_bytes\u001b[0;34m(bs, safe)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \"\"\"\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quote_from_bytes() expected bytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: quote_from_bytes() expected bytes"
     ]
    }
   ],
   "source": [
    "# search = gn.search(‘Article_Title’) #search by reference to peer reviewed article title\n",
    "def scraping_title(df):\n",
    "    stories = []\n",
    "    for i in range(len(df)):\n",
    "        search = gn.search(df.iloc[i].loc['Article_Title'])\n",
    "        newsitem = search['entries']\n",
    "        for item in newsitem:\n",
    "            story = {\n",
    "                'Article_Title': df.iloc[i].loc['Article_Title'],\n",
    "                'title': item.title,\n",
    "                'link': item.link\n",
    "            }\n",
    "            \n",
    "            stories.append(story)    \n",
    "    return stories\n",
    "scraping_title_df = pd.DataFrame(scraping_title(df)) # this puts the output in a long form dataframe\n",
    "\n",
    "scraping_title_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9527a4b6",
   "metadata": {},
   "source": [
    "### Use keywords in peer-reviewed article titles to reduce irrelevant return items from the scraping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will use code from the keywords search above, tbd \n",
    "\n",
    "# get rid of punctuation\n",
    "\n",
    "# import string\n",
    "\n",
    "# article_titles = df['Article_Title'].to_string()\n",
    "\n",
    "# no_punc = article_titles.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# print(no_punc)\n",
    "# print(type(no_punc))\n",
    "\n",
    "article_titles = df['Article_Title'].to_list() # make article titles a list, must have for following chunk of code to work\n",
    "print('article_titles: ', article_titles)\n",
    "print(type(article_titles))\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "stops = {'this', 'that', 'a', 'is', \"and\", \"Determining\", \"Doing\", \"the\", \"People\", \"of\"}    \n",
    "words = article_titles[0].split()\n",
    "count = Counter(word for word in words if word not in stops).most_common(10) # we may want to figure out a way to remove all punctuation from titles first\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16a8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
